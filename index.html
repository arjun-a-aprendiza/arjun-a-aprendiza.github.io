<!DOCTYPE html>
<html lang="en">
  <head>
    <title>Jeannette Bohg</title>
    <meta
      name="description"
      content="Jeannette Bohg, Assistant Professor for Robotics at Stanford."
    />
    <meta charset="utf-8"/>

    <!-- Twitter data -->
    <meta name="twitter:card" content="summary" />
    <meta name="twitter:title" content="Jeannette Bohg" />
    <meta
      name="twitter:description"
      content="Jeannette Bohg, Assistant Professor for Robotics at Stanford."
    />
    <meta name="twitter:creator" content="@leto__jean" />
    <meta
      name="twitter:image"
      content="img/portrait_square.png"
    />

    <!-- Open Graph data -->
    <meta property="og:title" content="Jeannette Bohg" />
    <meta property="og:url" content="http://iprl.stanford.edu/" />
    <meta property="og:image" content="img/portrait_square.png" />
    <meta
      property="og:description"
      content="Jeannette Bohg, Assistant Professor for Robotics at Stanford."
    />
    <meta property="og:site_name" content="Jeannette Bohg" />

    <!-- Favicon/theme -->
<link rel="apple-touch-icon" sizes="180x180" href="img/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="img/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="img/favicon-16x16.png">
<link rel="manifest" href="/site.webmanifest">

    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, maximum-scale=1"
    />

    <link
      href="https://fonts.googleapis.com/css?family=Roboto+Mono"
      rel="stylesheet"
    />
    <link rel="stylesheet" href="./style.css" />
  </head>

  <body>
    <div class="container">
      <div class="header-section">
        <div class="header-frame">
          <h1>Jeannette Bohg</h1>
          <h2>Assistant Professor for Robotics at Stanford</h2>
        </div>
        <div class="img-frame">
          <img id="propic" src="img/arjun.png" alt="" />
        </div>
      </div>
      <div class="links">
        <a href="http://iprl.stanford.edu">iprl</a>
        <a href="http://iprl.stanford.edu/index.html#news">news</a>
        <a href="http://iprl.stanford.edu/publications">publications</a>
        <a href="http://iprl.stanford.edu/index.html#teaching">teaching</a>
        <a href="http://twitter.com/leto__jean">twitter</a>
        <a href="https://scholar.google.com/citations?user=rjnJnEkAAAAJ&hl=en/">scholar</a>
        <script language="JavaScript" type="text/javascript">
          var part1 = "bohg";
          var part2 = Math.pow(2,6);
          var part3 = "contact";
          var part4 = "stanford.edu";
          var part5 = part1 + String.fromCharCode(part2) + part4;
          document.write("<a href=" + "mai" + "lto" + ":" + part5 + ">" + part3 + "</a>");
        </script>
        <!--a href=" ">contact</a-->
      </div>
      <div class="bio-switcher">
        <div class="toggler">
          <button id="short" class="show">Short</button>
          <button id="long">Long</button>
          <button id="speaker">Speaker</button>
        </div>
        <div class="bio short show">
          I'm a Professor for Robotics at Stanford University. I'm also directing the
          <a href="http://iprl.stanford.edu">Interactive Perception and Robot Learning Lab</a>.  In general, my research explores two questions: What are the underlying principles of robust sensorimotor coordination in humans, and how we can implement them on robots? Research on this topic has to necessarily be at the intersection of Robotics, Machine Learning and Computer Vision. In my lab, we are specifically interested Robotic Grasping and Manipulation.  
        </div>
        <div class="bio long">
          I'm a Professor for Robotics and part of the <a href="https://ai.stanford.edu/">Stanford AI lab</a> 
          within the Computer Science Department of Stanford University. I'm also directing the 
          <a href="http://iprl.stanford.edu">Interactive Perception and Robot Learning Lab</a>, and
          enjoy research at the intersection of Robotics, Machine Learning and Computer Vision. 
          Previously, I was a group leader at the <a href="https://am.is.tuebingen.mpg.de/">
          Autonomous Motion Department (AMD)</a> of the MPI for Intelligent Systems. My favourite 
          robot will always be <a href="https://am.is.tuebingen.mpg.de/pages/robots">Apollo</a>. 
          Before joining the MPI in 2012, I did my PhD at the <a href="https://www.kth.se/rpl"> Division of Robotics, Perception and Learning</a> (RPL) at KTH in Stockholm.
          In my thesis, I proposed novel methods towards multi-modal scene understanding for robotic grasping. I did my undergrad in Computer Science at the Technical University in Dresden. Well, actually it was a Diploma. Maybe today it would be called a coterm. I also studied Art and Technology at Chalmers in Gothenburg, which was incredibly fun. 
          In general, my research explores two questions: What are the underlying principles of robust sensorimotor coordination in humans, and how we can implement them on robots? My generous guess is that we will need a few more years to find out. We will keep searching. And hopefully some day, these robots will finally step out of the lab and become truly useful to people in the real world. 
        </div>
        <div class="bio speaker">
          Jeannette Bohg is an Assistant Professor of Computer Science at Stanford University. She was a group leader at the Autonomous Motion Department (AMD) of the MPI for Intelligent Systems until September 2017. Before joining AMD in January 2012, Jeannette Bohg was a PhD student at the Division of Robotics, Perception and Learning (RPL) at KTH in Stockholm. In her thesis, she proposed novel methods towards multi-modal scene understanding for robotic grasping. She also studied at Chalmers in Gothenburg and at the Technical University in Dresden where she received her Master in Art and Technology and her Diploma in Computer Science, respectively. Her research focuses on perception and learning for autonomous robotic manipulation and grasping. She is specifically interested in developing methods that are goal-directed, real-time and multi-modal such that they can provide meaningful feedback for execution and learning.
          Jeannette Bohg has received several Early Career and Best Paper awards, most notably the 2019 IEEE Robotics and Automation Society Early Career Award and the 2020 Robotics: Science and Systems Early Career Award.
        </div>



      </div>

      <div class="dark-mode-toggler">
        <input type="checkbox" id="toggler" />
        <label for="toggler" aria-label="Toggler for Dark Mode"></label>
      </div>
    </div>


    <div class="attribution">
      Website adapted from <a href="http://cassidoo.co/">Cassidy Williams</a> with permission.
    </div>


    <script src="./script.js"></script>

  </body>
</html>
